---
title: "**How consumers are using their fitness tracker**<br /> Bellabeat case study with SQL"
author: "PhatLV"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---
<br>
*(Not interested in SQL? [Switch to Bellabeat Casestudy with R](https://phatle96.github.io/BellabeatCasestudy))*

# 0. Introduction

***Welcome to the Bellabeat data analysis case study!***

In this case study, I will perform many real-world tasks of a junior data analyst. I will imagine that I am working for Bellabeat, a high-tech manufacturer of health-focused products for women, and meet different characters and team members.

In order to answer the key business questions, I will follow the steps of the data analysis process: ask, prepare, process, analyze, share, and act.

## 0.1 Scenario

I am a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the global smart device market.

Urška Sršen, co-founder and Chief Creative Officer of Bellabeat, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company.

I have been asked to focus on one of Bellabeat's products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights I discover will then help guide marketing strategy for the company. I will present my analysis to the Bellabeat executive team along with high-level recommendations for Bellabeat's marketing strategy

## 0.2 Characters & Products

### 0.2.1. Characters

**Urška Sršen**: Bellabeat's co-founder and Chief Creative Officer

**Sando Mur**: Mathematician and Bellabeat's cofounder; key member of the Bellabeat executive team

**Bellabeat marketing analytics team**: A team of data analysts responsible for collecting, analyzing, and reporting data that helps guide Bellabeat's marketing strategy. I joined this team six months ago and have been busy learning about Bellabeat's mission and business goals - as well as how I, as a junior data analyst, can help Bellabeat achieve them

### 0.2.2 Products

**Bellabeat app**: The Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and make healthy decisions. The Bellabeat app connects to their line of smart wellness products

**Leaf**: Bellabeat's classic wellness tracker can be worn as a bracelet, necklace, or clip. The Leaf tracker connects to the Bellabeat app to track activity, sleep, and stress.

**Time**: This wellness watch combines the timeless look of a classic timepiece with smart technology to track user activity, sleep, and stress. The Time watch connects to the Bellabeat app to provide you with insights into your daily wellness.

**Spring**: This is a water bottle that tracks daily water intake using smart technology to ensure that you are appropriately hydrated throughout the day. The Spring bottle connects to the Bellabeat app to track your hydration levels.

**Bellabeat membership**: Bellabeat also offers a subscription-based membership program for users. Membership gives users 24/7 access to fully personalized guidance on nutrition, activity, sleep, health and beauty, and mindfulness based on their lifestyle and goals.

## 0.3 About the company

Urška Sršen and Sando Mur founded Bellabeat, a high-tech company that manufactures health-focused smart products. Sršen used her background as an artist to develop beautifully designed technology that informs and inspires women around the world. Collecting data on activity, sleep, stress, and reproductive health has allowed Bellabeat to empower women with knowledge about their own health and habits.

Since it was founded in 2013, Bellabeat has grown rapidly and quickly positioned itself as a tech-driven wellness company for women. By 2016, Bellabeat had opened offices around the world and launched multiple products. Bellabeat products became available through a growing number of online retailers in addition to their own e-commerce channel on their website.

The company has invested in traditional advertising media, such as radio, out-of-home billboards, print, and television, but focuses on digital marketing extensively. Bellabeat invests year-round in Google Search, maintaining active Facebook and Instagram pages, and consistently engages consumers on Twitter. Additionally, Bellabeat runs video ads on Youtube and display ads on the Google Display Network to support campaigns around key marketing dates.

Sršen knows that an analysis of Bellabeat's available consumer data would reveal more opportunities for growth. She has asked the marketing analytics team to focus on a Bellabeat product and analyze smart device usage data in order to gain insight into how people are already using their smart devices. Then, using this information, she would like high-level recommendations for how these trends can inform Bellabeat marketing strategy.

___

# 1. Business task summary

***A clear statement of the business task***

## 1.1 Purpose

The goal of this project is to study how consumers are using their smart fitness device. The project will identify trends in the smart fitness device data. After identifying trends, select one Bellabeat product to apply these insights to identify recommendations that can inform Bellabeat marketing strategy.

The final deliverable will provide recommendations about how consumers are using their smart device.

## 1.2 Deliverables

Produce a report with the following deliverables:

1.  A clear summary of the business task
2.  A description of all data sources used
3.  Documentation of any cleaning or manipulation of data
4.  A summary of analysis
5.  Supporting visualizations and key findings
6.  Top high-level content recommendations based on analysis

___

# 2. Prepare 

***A description of all data sources used***

## 2.1 Data sources

In this task, I was given a public data set that explores smart device users' daily habits that is [FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit) and was stored on Kaggle by Mobius with [CC0 liscense](https://creativecommons.org/publicdomain/zero/1.0/)

But after the explorer, we figured out that the data is copyright with [CCBY - Attribution](https://creativecommons.org/licenses/by/4.0/legalcode) license, and originally stored on [Zenodo](https://zenodo.org/record/53894#.YoD7HNpBy02), so if we use this data, we are required attribution to the creator and include the BY element.

So we will use the original data stored on Zenodo and cite Furberg, R., Brinton, J., Keating, M., & Ortiz, A. (2016). Crowd-sourced Fitbit datasets 03.12.2016-05.12.2016 [Data set]. Zenodo. [\@furberg2016](https://doi.org/10.5281/zenodo.53894)\
*(Zenodo is a general-purpose open repository developed under the European OpenAIRE program and operated by CERN. It allows researchers to deposit research papers, data sets, research software, reports, and other digital artifacts.)*

**Content:**

-   These datasets were generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016.

-   Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.

-   Individual reports can be parsed by export session ID (column A) or timestamp (column B). Variation between output represents the use of different types of Fitbit trackers and individual tracking behaviors/preferences.

After downloading data, we got two compressed files named by two periods of time, the first is from 03/12/2016 to 04/11/2016 and another is from 04/12/2016 to 05/12/2016

![The raw data](../documents/image/1.png)

Extract them, we got

![Data from 03/12/2016 to 04/11/2016](../documents/image/3.png)

![Data from 04/12/2016 to 05/12/2016](../documents/image/2.png)

It looks like some of the data from the first period time are missing. We will explore that later on. First, we are going to import and merge data that are available during the whole period

## 2.2 Import

Because BigQuery only accept values in date columns must use 
the dash (-) separator and the date must be in the following 
format: "YYYY-MM-DD" (year-month-day), but date columns in our dataset is in format "MM/DD/YYYY I:M:S p" so we add table in to Bigquery and edit schema of date columns into String type. Then use `select parse_datetime(format_string, datetime_string)` to return datetime type of date columns with format_string is "%m/%d/%Y %I:%M:%S %p"

## 2.3 Merge

Using the UNION operator to merge two-period time into one, after that, notice we are missing some of the whole time data that include

-   `dailyCalories`
-   `dailyIntensities`
-   `dailySteps`
-   `minuteCaloriesWide`
-   `minuteIntensitiesWide`
-   `minuteStepsWide`
-   `minuteMETsWide`
-   `sleepDay`

## 2.4 Data integrity

Let the data be integrity that must conform to principles are accuracy, completeness, consistency, and trustworthiness throughout its life cycle

1.  Accuracy is the degree to which the data conforms to the actual entity being measured or described, so we will check the relation of variables in the merging table in each hierarchy of time from minute to hourly to daily

2.  Completeness is the degree to which the data contains all desired components or measures, so we will check missing data in a minute, hourly, and daily and the effect on data validity

3.  Consistency is the degree to which the data is repeatable from different points of entry or collection, so we will check data type consistency in the date-time hierarchy

4.  And trustworthiness is checked for bias and credibility in the data that are Reliable, Original, Comprehensive, Current, and Cited

    -   Reliable: Due to the sample size being 30 that is the smallest sample size for which the Central Limit Theorem is still valid, but this sample size is not having any demographic information so we could encounter a sampling bias
    -   Original: This data was generated by a third-party provider - respondents to a distributed survey via Amazon Mechanical Turk so this data is not original from Fitbit
    -   Comprehensive: Parameters match most of the Bellabeat products' parameters
    -   Current: Data is 5 years old and may not be relevant
    -   Cited: cited as [Furberg, R., Brinton, J., Keating, M., & Ortiz, A. (2016)](https://doi.org/10.5281/zenodo.53894)

## 2.5 Data limitations

-   Data is collected 6 years ago in 2016. Users' daily activity, fitness and sleeping habits, diet, and food consumption may have changed since then. Data may not be timely or relevant.
-   Sample size of 30 FitBit users with no any demographic information so we are not sure if the sample is representative of the population as a whole.
-   As data is collected in a survey, we are unable to ascertain its integrity or accuracy.

___

# 3. Process

## 3.1 Activity data
### 3.1.1 Daily

In the `dailyActivity` data, every minute during a day is an active minute is measured by sedentary, lightly, fairly, and very active minutes.

1440 is the total number of minutes in a day, if the total number of active minutes in a day is not equal to 1440 so that day exists missing data

```{sql, eval = F}
SELECT
  *
FROM (
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.dailyActivity`)
WHERE
  (very_active_minutes + fairly_active_minutes + lightly_active_minutes + sedentary_minutes) = 1440
```

After querying, we got 711 rows of valid data per 1397 rows of the `dailyActivity` data. So the complete rate of data is only 50.8%.

Next, we check to hourly activity data

### 3.1.2 Hourly

Figure out that the total of record in the `hourlyCalories`, `hourlyIntensities`, and `hourlySteps` data is the same, after filter duplicate data out of them, we join it into the `hourlyActivity` data.

Now we check the complete rate of the `hourlyActivity` data by use the window function to count the total number of hour in a day, if that is not equal to 24 then filter it out of the table

```{sql, eval = F}
CREATE TABLE IF NOT EXISTS fitabase_data.hourlyActivity AS
/*1. Filter duplicate out of tables to combine all of that together in the next step*/
WITH
  hourlyCalories AS(
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.hourlyCalories`),
  hourlyIntensities AS(
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.hourlyIntensities`),
  hourlySteps AS(
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.hourlySteps`)
/*4. Filter data that have the total number of hours in date is not equal to 24*/
SELECT
  * EXCEPT(count_hour)
FROM (
/*3. Use the window function to count the total number of hour in a day, if that is not equal to 24 then filter it out of the table*/
  SELECT
    *,
    COUNT(activity_hour) OVER(PARTITION BY id, EXTRACT(date FROM activity_hour) ) AS count_hour
  FROM (
/*2. Join table*/
    SELECT
      *
    FROM
      hourlyCalories
    INNER JOIN
      hourlyIntensities
    USING
      (id,
        activity_hour)
    INNER JOIN
      hourlySteps
    USING
      (id,
        activity_hour)) )
WHERE
  count_hour = 24;
```

After querying, we got 45384 rows of valid data per 46008 total rows of hourly activity data. We got the complete rate is 98.6% that many times more than the `dailyActivity` data

Next, we continue with the minute activity data

### 3.1.3 Minute

Similar to the `hourlyActivity` data, we create the `minuteActivity` data by join the minute activity data of calories, intensities, steps, and METs using `id` and `activity_minute`

Then using the window function to create the intermediary column to count the total number of minutes in a day, and create columns of the previous mets and calories values to fill in the zero values in that variables


```{sql, eval = F}
CREATE TABLE IF NOT EXISTS fitabase_data.minuteActivity AS
/*1. Filter duplicate out of tables to combine all of that together in the next step*/
WITH
  minuteCalories AS(
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.minuteCaloriesNarrow`),
  minuteIntensities AS(
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.minuteIntensitiesNarrow`),
  minuteSteps AS(
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.minuteStepsNarrow`),
  minuteMETs AS(
  SELECT
    DISTINCT *
  FROM
    `data-analysis-case-study-2022.fitabase_data.minuteMETsNarrow`)
/*4. 
a. Filter out of values that are not equal to 1440 minutes
b. Fill in the zero values in the mets and calories*/
SELECT
  * EXCEPT(count_minutes,
    lag_mets,
    lag_calories,
    mets,
    calories),
  CASE mets
    WHEN 0 THEN lag_mets
  ELSE
  mets
  END
  AS mets,
  CASE calories
    WHEN 0 THEN lag_calories
  ELSE
  calories
  END
  AS calories
FROM (
/*3.
a. Create count_minutes to count the total number of minutes in a day, if not equal to 1440 minutes then filter all of the records on that day out of the table
b. Create lag_mets and lag_calories to get the previous value of the mets and the calories to fill in the zero values to both of them in the next steps*/
  SELECT
    *,
    COUNT(activity_minute)OVER(PARTITION BY id, EXTRACT(date FROM activity_minute) ) AS count_minutes,
    LAG(mets, 1) OVER(PARTITION BY id ORDER BY activity_minute ) AS lag_mets,
    LAG(calories, 1) OVER(PARTITION BY id ORDER BY activity_minute ) AS lag_calories
  FROM (
#2. Join table
    SELECT
      * EXCEPT(me_ts),
      me_ts AS mets
    FROM
      minuteCalories
    INNER JOIN
      minuteIntensities
    USING
      (id,
        activity_minute)
    INNER JOIN
      minuteSteps
    USING
      (id,
        activity_minute)
    INNER JOIN
      minuteMETs
    USING
      (id,
        activity_minute) ) )
WHERE
  count_minutes = 1440
```

After querying, we got 2.723.040 valid value per 2.760.120 total number of rows of the minute activity data with the complete rate is 98.6% that is the same with hourly data

Next we try to aggregate the minute data into the hourly and daily activity data

#### a. Transform to Hourly

The hourly activity data is aggregated from the sum of the minute activity data of the calories, intensities and steps, and the average of the minute intensity data per hour

```{sql, eval = F}
CREATE TABLE IF NOT EXISTS
  fitabase_data.hourlyActivityProcessed AS
/*1. Extract date and hour from activity_minute to CONCAT into activity_hour in the next step*/
WITH
  minuteActivity AS(
  SELECT
    *,
    EXTRACT(date
    FROM
      activity_minute) AS date,
    EXTRACT(hour
    FROM
      activity_minute) AS hour
  FROM
    `data-analysis-case-study-2022.fitabase_data.minuteActivity` AS minuteActivity)
/*2. Aggregate data by activity_hour*/
SELECT
  id,
  CAST(CONCAT(date, " ", hour, ":00:00") AS timestamp) AS activity_hour,
  ROUND(SUM(calories)) AS calories,
  SUM(intensity) AS total_intensity,
  ROUND(AVG(intensity), 5) AS average_intensity,
  SUM(steps) AS step_total
FROM
  minuteActivity
GROUP BY
  id,
  activity_hour;
```

After querying, we got 46002 rows of valid data that is more than the original hourly activity data with 45384 total valid rows

Next, we continue to transform minute data into daily data 

#### b. Transform to Daily

The daily data is aggregated from the total of active minutes and the sum of steps and calories that are grouped by intensity levels then pivot to the wider data

```{sql, eval = F}
CREATE TABLE IF NOT EXISTS
  fitabase_data.dailyActivityProcessed AS
/*1. Create dailyAcivity aggregated by activity_date and intensity*/
WITH
  dailyActivity AS(
  SELECT
    id,
    EXTRACT(date
    FROM
      activity_minute) AS activity_date,
    intensity,
    SUM(steps) AS total_steps,
    SUM(steps) / 1312.33595801 AS total_distance,
    COUNT(DISTINCT activity_minute) AS active_minute,
    SUM(calories) AS total_calories
  FROM
    `data-analysis-case-study-2022.fitabase_data.minuteActivity`
  GROUP BY
    id,
    activity_date,
    intensity)
/*5. Calculate total number of steps, distances and calories*/
SELECT
  id,
  activity_date,
  ROUND(sedentary_steps + lightly_steps + moderately_steps + very_steps, 2) AS total_steps,
  ROUND(sedentary_active_distance + lightly_active_distance + moderately_active_distance + very_active_distance, 2) AS total_distance,
  ROUND(sedentary_active_distance, 2) AS sedentary_active_distance,
  ROUND(lightly_active_distance, 2) AS lightly_active_distance,
  ROUND(moderately_active_distance, 2) AS moderately_active_distance,
  ROUND(very_active_distance, 2) AS very_active_distance,
  sedentary_active_minutes,
  lightly_active_minutes,
  moderately_active_minutes,
  very_active_minutes,
  ROUND(sedentary_calories + lightly_calories + moderately_calories + very_calories) AS calories
FROM (
/*4. Replace NULL values into zero values*/
  SELECT
    id,
    activity_date,
    ifnull(steps_0,
      0) AS sedentary_steps,
    ifnull(steps_1,
      0) AS lightly_steps,
    ifnull(steps_2,
      0) AS moderately_steps,
    ifnull(steps_3,
      0) AS very_steps,
    ifnull(distance_0,
      0) AS sedentary_active_distance,
    ifnull(distance_1,
      0) AS lightly_active_distance,
    ifnull(distance_2,
      0) AS moderately_active_distance,
    ifnull(distance_3,
      0) AS very_active_distance,
    ifnull(active_minute_0,
      0) AS sedentary_active_minutes,
    ifnull(active_minute_1,
      0) AS lightly_active_minutes,
    ifnull(active_minute_2,
      0) AS moderately_active_minutes,
    ifnull(active_minute_3,
      0) AS very_active_minutes,
    ifnull(calories_0,
      0) AS sedentary_calories,
    ifnull(calories_1,
      0) AS lightly_calories,
    ifnull(calories_2,
      0) AS moderately_calories,
    ifnull(calories_3,
      0) AS very_calories
  FROM
/*2. PIVOT dailyActivity data by value from intensity*/
    dailyActivity PIVOT( SUM(total_steps) AS steps,
      SUM(total_distance) AS distance,
      SUM(active_minute) AS active_minute,
      SUM(total_calories) AS calories FOR intensity IN (0,
        1,
        2,
        3)))
```

After querying, we got 1935 rows of valid data that is more than the original daily activity data with 711 total valid rows.
The activity data in the time hierarchy is inconsistent but the complete rate of the minute data is the highest so we will use it and the data is aggregated from it to analyze. 

## 3.2 Sleep data

We just got the half period time data of `sleepDay` data but we got the complete `minuteSleep` data. So we will transform `minuteSleep` data into `sleepDay` to complete it

```{sql, eval = F}
CREATE TABLE IF NOT EXISTS
  fitabase_data.sleepDayProcessed AS
/*1. Assume that the total of value 1 is total_minutes_asleep and the grand total of values 1, 2, 3 is total_time_in_bed
So we split value 1 into minute_asleep to sum it up in the next step
We also extract sleep_day from date to group data by sleep_day in the next step*/
WITH
  minuteSleep AS(
  SELECT
    *,
    CASE value
      WHEN 1 THEN 1
    ELSE
    0
  END
    AS minutes_asleep,
    EXTRACT(date
    FROM
      date) AS sleep_day
  FROM (
    SELECT
      DISTINCT *
    FROM
      `data-analysis-case-study-2022.fitabase_data.minuteSleep`))
/*2. Aggregate data by sleep_day per ID*/
SELECT
  id,
  sleep_day,
  COUNT(DISTINCT log_id) AS total_sleep_records,
  SUM(minutes_asleep) AS total_minutes_asleep,
  COUNT(*) AS total_time_in_bed
FROM
  minuteSleep
GROUP BY
  id,
  sleep_day;
```

___

# 4. Analyze
## 4.1 Activity data

Create the hourly activity data with more detail than the original hourly activity data by aggregate data from the minute activity data

```{sql, eval = F}
CREATE TABLE IF NOT EXISTS hourlyActivitySummary AS
WITH
  minuteActivity AS(
  SELECT
    *,
    EXTRACT(date
    FROM
      activity_minute) AS date,
    EXTRACT(hour
    FROM
      activity_minute) AS hour,
    CASE
      WHEN steps > 0 THEN 1
    ELSE
    0
  END
    AS step_minutes
  FROM
    `data-analysis-case-study-2022.fitabase_data.minuteActivity`)
SELECT
  *,
  sedentary_steps + lightly_steps + moderately_steps + very_steps AS total_steps,
  sedentary_steps_minutes + lightly_steps_minutes + moderately_steps_minutes + very_steps_minutes AS total_step_minutes,
  sedentary_calories + lightly_calories + moderately_calories + very_calories AS total_calories,
  sedentary_mets + lightly_mets + moderately_mets + very_mets AS total_mets
FROM (
  SELECT
    id,
    activity_hour,
    ifnull(steps_0,
      0) AS sedentary_steps,
    ifnull(steps_1,
      0) AS lightly_steps,
    ifnull(steps_2,
      0) AS moderately_steps,
    ifnull(steps_3,
      0) AS very_steps,
    ifnull(step_minutes_0,
      0) AS sedentary_steps_minutes,
    ifnull(step_minutes_1,
      0) AS lightly_steps_minutes,
    ifnull(step_minutes_2,
      0) AS moderately_steps_minutes,
    ifnull(step_minutes_3,
      0) AS very_steps_minutes,
    ifnull(active_minutes_0,
      0) AS sedentary_active_minutes,
    ifnull(active_minutes_1,
      0) AS lightly_active_minutes,
    ifnull(active_minutes_2,
      0) AS moderately_active_minutes,
    ifnull(active_minutes_3,
      0) AS very_active_minutes,
    ifnull(calories_0,
      0) AS sedentary_calories,
    ifnull(calories_1,
      0) AS lightly_calories,
    ifnull(calories_2,
      0) AS moderately_calories,
    ifnull(calories_3,
      0) AS very_calories,
    ifnull(mets_0,
      0) AS sedentary_mets,
    ifnull(mets_1,
      0) AS lightly_mets,
    ifnull(mets_2,
      0) AS moderately_mets,
    ifnull(mets_3,
      0) AS very_mets
  FROM (
    SELECT
      id,
      CAST(CONCAT(date, " ", hour, ":00:00") AS timestamp) AS activity_hour,
      intensity,
      SUM(steps) AS steps,
      SUM(step_minutes) AS step_minutes,
      COUNT(*) AS active_minutes,
      SUM(calories) AS calories,
      SUM(mets) AS mets
    FROM
      minuteActivity
    GROUP BY
      id,
      activity_hour,
      intensity ) PIVOT( SUM(steps) AS steps,
      SUM(step_minutes) AS step_minutes,
      SUM(active_minutes) AS active_minutes,
      SUM(calories) AS calories,
      SUM(mets) AS mets FOR intensity IN (0,
        1,
        2,
        3)))
```

## 4.2 Sleep data

Create the sleep log info data by aggregate data from the minute sleep data

```{sql, eval = F}
CREATE TABLE IF NOT EXISTS sleepLogInfo AS
WITH
  minuteSleep AS(
  SELECT
    *,
    CASE value
      WHEN 1 THEN 1
    ELSE
    0
  END
    AS minutes_asleep
  FROM (
    SELECT
      DISTINCT *
    FROM
      `data-analysis-case-study-2022.fitabase_data.minuteSleep`))
SELECT
  id,
  log_id,
  SUM(minutes_asleep) AS total_minutes_asleep,
  COUNT(*) AS total_time_in_bed,
  EXTRACT(date
  FROM
    MIN(date)) AS sleep_date,
  EXTRACT(date
  FROM
    MAX(date)) AS wake_date,
  EXTRACT(hour
  FROM
    MIN(date)) AS sleep_time,
  EXTRACT(hour
  FROM
    MAX(date)) AS wake_time,
  CASE EXTRACT(dayofweek
  FROM
    MIN(date))
    WHEN 1 THEN "Sun"
    WHEN 2 THEN "Mon"
    WHEN 3 THEN "Tue"
    WHEN 4 THEN "Wed"
    WHEN 5 THEN "Thu"
    WHEN 6 THEN "Fri"
    WHEN 7 THEN "Sat"
  ELSE
  "error"
END
  AS sleep_day,
  CASE EXTRACT(dayofweek
  FROM
    MAX(date))
    WHEN 1 THEN "Sun"
    WHEN 2 THEN "Mon"
    WHEN 3 THEN "Tue"
    WHEN 4 THEN "Wed"
    WHEN 5 THEN "Thu"
    WHEN 6 THEN "Fri"
    WHEN 7 THEN "Sat"
  ELSE
  "error"
END
  AS wake_day
FROM
  minuteSleep
GROUP BY
  id,
  log_id;
```

___

# 5. Share and Act

***Supporting visualizations and key findings***

I already uploaded the Bellabeat data presentation [on Tableau](https://public.tableau.com/app/profile/phatlv/viz/BellabeatCasestudy_16564986351180/Story1)

The presentation includes the analysis report, final conclusions, and recommendations based on the analysis